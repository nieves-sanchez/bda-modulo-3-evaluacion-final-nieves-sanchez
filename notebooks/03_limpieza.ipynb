{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e8bb41",
   "metadata": {},
   "source": [
    "# Limpieza y transformaci√≥n de datos\n",
    "\n",
    "En este notebook aplicamos las transformaciones necesarias detectadas durante el An√°lisis Exploratorio de Datos (EDA).\n",
    "\n",
    "El objetivo es obtener un dataset limpio, coherente y listo para el an√°lisis estad√≠stico final.\n",
    "\n",
    "---\n",
    "\n",
    "## Resumen de decisiones tomadas tras el EDA\n",
    "\n",
    "A partir del an√°lisis previo, se han definido las siguientes acciones de limpieza:\n",
    "\n",
    "\n",
    "### 1Ô∏è‚É£ Normalizaci√≥n de nombres de columnas\n",
    "\n",
    "- Aplicar `strip()` y convertir los nombres a formato `snake_case`.\n",
    "- Esto mejora la legibilidad y facilita el trabajo posterior con el dataset.\n",
    "  \n",
    "\n",
    "### 2Ô∏è‚É£ Variables categ√≥ricas\n",
    "\n",
    "- No se han detectado inconsistencias en las categor√≠as.\n",
    "- Se aplicar√° √∫nicamente `strip()` por seguridad para eliminar posibles espacios invisibles.\n",
    "- No se modificar√°n may√∫sculas/min√∫sculas ni se alterar√°n las categor√≠as originales.\n",
    "  \n",
    "\n",
    "### 3Ô∏è‚É£ Variable `Salary`\n",
    "\n",
    "- Existen valores negativos (0,12%), que son inconsistentes.\n",
    "- Existen valores nulos concentrados en el grupo `Education = College`.\n",
    "\n",
    "Decisi√≥n de tratamiento:\n",
    "- Los valores negativos se tratar√°n como inv√°lidos.\n",
    "- Tanto los negativos como los nulos se imputar√°n usando la **mediana del grupo educativo correspondiente**.\n",
    "- Para el grupo `College`, que no tiene salarios informados, se utilizar√° como referencia la mediana del grupo educativo m√°s cercano.\n",
    "\n",
    "El objetivo es no dejar valores nulos en `Salary` y aplicar una imputaci√≥n coherente y robusta frente a outliers.\n",
    "\n",
    "\n",
    "### 4Ô∏è‚É£ Cancelaci√≥n\n",
    "\n",
    "- Se crea una variable booleana `cancelled` (True/False) a partir de `Cancellation Year`:\n",
    "  - `True` cuando existe a√±o de cancelaci√≥n.\n",
    "  - `False` cuando no existe (valor faltante).\n",
    "\n",
    "- Las columnas `cancellation_year` y `cancellation_month` se mantienen como valores faltantes (`<NA>`) cuando el cliente no ha cancelado.\n",
    "  Estos valores no representan datos perdidos, sino un caso ‚Äúno aplica‚Äù.\n",
    "\n",
    "- Se convierten ambas columnas a tipo entero nullable (`Int64`) para evitar decimales innecesarios y mantener consistencia en el tipo de dato.\n",
    "\n",
    "De esta forma, mantenemos la coherencia sem√°ntica de las variables originales y facilitamos su uso posterior en an√°lisis estad√≠stico o modelos predictivos.\n",
    "\n",
    "\n",
    "### 5Ô∏è‚É£ Variables constantes\n",
    "\n",
    "- `Country` tiene un √∫nico valor (\"Canada\").\n",
    "- Se eliminar√° del dataset por no aportar informaci√≥n anal√≠tica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9338dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset cargado\n",
      "Filas: 401688 | Columnas: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loyalty Number</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Flights Booked</th>\n",
       "      <th>Flights with Companions</th>\n",
       "      <th>Total Flights</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Points Accumulated</th>\n",
       "      <th>Points Redeemed</th>\n",
       "      <th>Dollar Cost Points Redeemed</th>\n",
       "      <th>Country</th>\n",
       "      <th>Province</th>\n",
       "      <th>City</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Loyalty Card</th>\n",
       "      <th>CLV</th>\n",
       "      <th>Enrollment Type</th>\n",
       "      <th>Enrollment Year</th>\n",
       "      <th>Enrollment Month</th>\n",
       "      <th>Cancellation Year</th>\n",
       "      <th>Cancellation Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100018</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1521</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>T9G 1W3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>92552.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>7919.2</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100018</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1320</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>T9G 1W3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>92552.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>7919.2</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100018</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>2533</td>\n",
       "      <td>253.0</td>\n",
       "      <td>438</td>\n",
       "      <td>36</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>T9G 1W3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>92552.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>7919.2</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loyalty Number  Year  Month  Flights Booked  Flights with Companions  \\\n",
       "0          100018  2017      1               3                        0   \n",
       "1          100018  2017      2               2                        2   \n",
       "2          100018  2017      3              14                        3   \n",
       "\n",
       "   Total Flights  Distance  Points Accumulated  Points Redeemed  \\\n",
       "0              3      1521               152.0                0   \n",
       "1              4      1320               132.0                0   \n",
       "2             17      2533               253.0              438   \n",
       "\n",
       "   Dollar Cost Points Redeemed Country Province      City Postal Code  Gender  \\\n",
       "0                            0  Canada  Alberta  Edmonton     T9G 1W3  Female   \n",
       "1                            0  Canada  Alberta  Edmonton     T9G 1W3  Female   \n",
       "2                           36  Canada  Alberta  Edmonton     T9G 1W3  Female   \n",
       "\n",
       "  Education   Salary Marital Status Loyalty Card     CLV Enrollment Type  \\\n",
       "0  Bachelor  92552.0        Married       Aurora  7919.2        Standard   \n",
       "1  Bachelor  92552.0        Married       Aurora  7919.2        Standard   \n",
       "2  Bachelor  92552.0        Married       Aurora  7919.2        Standard   \n",
       "\n",
       "   Enrollment Year  Enrollment Month  Cancellation Year  Cancellation Month  \n",
       "0             2016                 8                NaN                 NaN  \n",
       "1             2016                 8                NaN                 NaN  \n",
       "2             2016                 8                NaN                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================\n",
    "# 1) Imports + carga del dataset unido (sucio)\n",
    "# =========================================\n",
    "\n",
    "\"\"\"\n",
    "Cargamos el dataset unido (sin limpiar) que generamos en el notebook de merge.\n",
    "Configuramos pandas para ver mejor resultados durante el proceso.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "\n",
    "ruta_entrada = \"../data/processed/dataset_unido.csv\"\n",
    "df = pd.read_csv(ruta_entrada)\n",
    "\n",
    "print(\"‚úÖ Dataset cargado\")\n",
    "print(\"Filas:\", df.shape[0], \"| Columnas:\", df.shape[1])\n",
    "display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e239f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 2) Funci√≥n de limpieza + guardado\n",
    "# =========================================\n",
    "\n",
    "def limpiar_dataset(df, ruta_salida=\"../data/processed/cleaned_customer_loyalty_flights.csv\"):\n",
    "    \"\"\"\n",
    "    Limpia y transforma el dataset unido siguiendo las decisiones tomadas tras el EDA.\n",
    "\n",
    "    Acciones principales:\n",
    "    1) Normaliza nombres de columnas a snake_case.\n",
    "    2) Aplica strip() a variables categ√≥ricas (sin cambiar may√∫sculas/min√∫sculas).\n",
    "    3) Crea la variable booleana 'cancelled' y ajusta tipos de cancelaci√≥n.\n",
    "    4) Limpia Salary: negativos -> imputaci√≥n + nulos -> imputaci√≥n por mediana de Education.\n",
    "       - Caso especial: Education='College' no tiene salarios -> fallback con mediana de Bachelor.\n",
    "    5) Elimina 'Country' si es constante (un √∫nico valor).\n",
    "    6) Guarda el dataset limpio en CSV.\n",
    "\n",
    "    Nota:\n",
    "    - No se eliminan outliers autom√°ticamente.\n",
    "    - Cancellation Year/Month se mantienen como NaN cuando no aplica.\n",
    "    \"\"\"\n",
    "\n",
    "    df_limpio = df.copy()\n",
    "\n",
    "    print(\"üßπ INICIO LIMPIEZA\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"Filas iniciales:\", df_limpio.shape[0], \"| Columnas iniciales:\", df_limpio.shape[1])\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 1) Normalizar nombres de columnas (snake_case)\n",
    "    # -------------------------------------------------\n",
    "    print(\"\\n1) Normalizando nombres de columnas (snake_case)...\")\n",
    "\n",
    "    columnas_originales = df_limpio.columns.tolist()\n",
    "\n",
    "    def a_snake_case(texto):\n",
    "        \"\"\"\n",
    "        Convierte un texto a snake_case de forma simple:\n",
    "        - strip\n",
    "        - lower\n",
    "        - reemplaza espacios por _\n",
    "        \"\"\"\n",
    "        texto = texto.strip().lower()\n",
    "        texto = texto.replace(\" \", \"_\")\n",
    "        return texto\n",
    "\n",
    "    df_limpio.columns = [a_snake_case(col) for col in df_limpio.columns]\n",
    "\n",
    "    print(\"‚úÖ Columnas normalizadas. Ejemplos:\")\n",
    "    print(\"Antes:\", columnas_originales[:5])\n",
    "    print(\"Despu√©s:\", df_limpio.columns.tolist()[:5])\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 2) Strip en categ√≥ricas (por seguridad)\n",
    "    # -------------------------------------------------\n",
    "    print(\"\\n2) Aplicando strip() en columnas categ√≥ricas...\")\n",
    "\n",
    "    columnas_categoricas = df_limpio.select_dtypes(include=\"object\").columns.tolist()\n",
    "\n",
    "    # Aplicamos strip solo a texto\n",
    "    for col in columnas_categoricas:\n",
    "        df_limpio[col] = df_limpio[col].astype(str).str.strip()\n",
    "\n",
    "        # Al convertir a str, los NaN pasan a \"nan\".\n",
    "        # En el EDA hemos comprobado que en el dataset las categ√≥ricas no ten√≠an nulos, pero por seguridad:\n",
    "        df_limpio[col] = df_limpio[col].replace(\"nan\", np.nan)\n",
    "\n",
    "    print(\"‚úÖ Strip aplicado a:\", len(columnas_categoricas), \"columnas categ√≥ricas\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 3) Cancelaci√≥n: crear cancelled + ajustar tipos\n",
    "    # -------------------------------------------------\n",
    "    print(\"\\n3) Creando variable 'cancelled' y ajustando tipos de cancelaci√≥n...\")\n",
    "\n",
    "    # Creamos booleano a partir de cancellation_year (NaN => no cancelado)\n",
    "    df_limpio[\"cancelled\"] = df_limpio[\"cancellation_year\"].notna()\n",
    "\n",
    "    # Convertimos year/month a Int64 nullable (mantiene NaN)\n",
    "    df_limpio[\"cancellation_year\"] = df_limpio[\"cancellation_year\"].astype(\"Int64\")\n",
    "    df_limpio[\"cancellation_month\"] = df_limpio[\"cancellation_month\"].astype(\"Int64\")\n",
    "\n",
    "    print(\"‚úÖ 'cancelled' creada. Distribuci√≥n:\")\n",
    "    display(df_limpio[\"cancelled\"].value_counts().to_frame(name=\"frecuencia\"))\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 4) Salary: negativos y nulos\n",
    "    # -------------------------------------------------\n",
    "    print(\"\\n4) Limpieza e imputaci√≥n de 'salary'...\")\n",
    "\n",
    "    # a) Contar negativos antes\n",
    "    negativos_salary = (df_limpio[\"salary\"] < 0).sum()\n",
    "    nulos_salary = df_limpio[\"salary\"].isna().sum()\n",
    "    print(\"Salarios negativos detectados:\", negativos_salary)\n",
    "    print(\"Nulos en salary detectados:\", nulos_salary)\n",
    "\n",
    "    # b) Convertir negativos a NaN (tratarlos como inv√°lidos)\n",
    "    df_limpio.loc[df_limpio[\"salary\"] < 0, \"salary\"] = np.nan\n",
    "\n",
    "    # c) Medianas por Education (solo para grupos con datos)\n",
    "    mediana_por_edu = df_limpio.groupby(\"education\")[\"salary\"].median()\n",
    "\n",
    "    # d) Fallback para College (no tiene salarios): usar mediana de Bachelor si existe\n",
    "    mediana_bachelor = mediana_por_edu.get(\"Bachelor\", np.nan)\n",
    "\n",
    "    if pd.isna(mediana_bachelor):\n",
    "        # Si por alg√∫n motivo no existe Bachelor (muy raro), usamos mediana global\n",
    "        mediana_bachelor = df_limpio[\"salary\"].median()\n",
    "\n",
    "    print(\"Mediana Salary (Bachelor) usada como fallback para College:\", mediana_bachelor)\n",
    "\n",
    "    # e) Imputaci√≥n por Education:\n",
    "    # - Si education != College: rellenar con mediana de su grupo\n",
    "    # - Si education == College: rellenar con mediana_bachelor\n",
    "    # Nota: hacemos esto en pasos simples para que sea f√°cil de entender.\n",
    "\n",
    "    # Primero imputamos donde hay mediana definida por grupo\n",
    "    df_limpio[\"salary\"] = df_limpio[\"salary\"].fillna(df_limpio[\"education\"].map(mediana_por_edu))\n",
    "\n",
    "    # Luego, lo que siga siendo NaN (principalmente College) lo rellenamos con fallback Bachelor\n",
    "    df_limpio.loc[df_limpio[\"salary\"].isna(), \"salary\"] = mediana_bachelor\n",
    "\n",
    "    # Comprobaci√≥n final salary\n",
    "    print(\"‚úÖ Salary tras imputaci√≥n:\")\n",
    "    print(\"Nulos en salary:\", df_limpio[\"salary\"].isna().sum())\n",
    "    print(\"M√≠nimo salary:\", df_limpio[\"salary\"].min())\n",
    "    print(\"M√°ximo salary:\", df_limpio[\"salary\"].max())\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 5) Eliminar Country si es constante\n",
    "    # -------------------------------------------------\n",
    "    print(\"\\n5) Eliminando 'country' si es constante...\")\n",
    "\n",
    "    if \"country\" in df_limpio.columns:\n",
    "        n_paises = df_limpio[\"country\"].nunique(dropna=False)\n",
    "        print(\"Valores √∫nicos en country:\", n_paises)\n",
    "\n",
    "        if n_paises == 1:\n",
    "            df_limpio = df_limpio.drop(columns=[\"country\"])\n",
    "            print(\"‚úÖ 'country' eliminada (no aporta informaci√≥n).\")\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è 'country' se mantiene (tiene m√°s de un valor).\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 6) Guardar CSV limpio\n",
    "    # -------------------------------------------------\n",
    "    print(\"\\n6) Guardando dataset limpio...\")\n",
    "    df_limpio.to_csv(ruta_salida, index=False)\n",
    "\n",
    "    print(\"‚úÖ Guardado completado:\", ruta_salida)\n",
    "    print(\"Filas finales:\", df_limpio.shape[0], \"| Columnas finales:\", df_limpio.shape[1])\n",
    "\n",
    "    # Resumen final de nulos\n",
    "    print(\"\\nüìå Resumen final de nulos (top 10):\")\n",
    "    display(df_limpio.isna().sum().sort_values(ascending=False).head(10).to_frame(name=\"nulos\"))\n",
    "\n",
    "    return df_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1d6785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ INICIO LIMPIEZA\n",
      "------------------------------------------------------------\n",
      "Filas iniciales: 401688 | Columnas iniciales: 25\n",
      "\n",
      "1) Normalizando nombres de columnas (snake_case)...\n",
      "‚úÖ Columnas normalizadas. Ejemplos:\n",
      "Antes: ['Loyalty Number', 'Year', 'Month', 'Flights Booked', 'Flights with Companions']\n",
      "Despu√©s: ['loyalty_number', 'year', 'month', 'flights_booked', 'flights_with_companions']\n",
      "\n",
      "2) Aplicando strip() en columnas categ√≥ricas...\n",
      "‚úÖ Strip aplicado a: 9 columnas categ√≥ricas\n",
      "\n",
      "3) Creando variable 'cancelled' y ajustando tipos de cancelaci√≥n...\n",
      "‚úÖ 'cancelled' creada. Distribuci√≥n:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frecuencia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancelled</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>352080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>49608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           frecuencia\n",
       "cancelled            \n",
       "False          352080\n",
       "True            49608"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4) Limpieza e imputaci√≥n de 'salary'...\n",
      "Salarios negativos detectados: 480\n",
      "Nulos en salary detectados: 101712\n",
      "Mediana Salary (Bachelor) usada como fallback para College: 72026.0\n",
      "‚úÖ Salary tras imputaci√≥n:\n",
      "Nulos en salary: 0\n",
      "M√≠nimo salary: 15609.0\n",
      "M√°ximo salary: 407228.0\n",
      "\n",
      "5) Eliminando 'country' si es constante...\n",
      "Valores √∫nicos en country: 1\n",
      "‚úÖ 'country' eliminada (no aporta informaci√≥n).\n",
      "\n",
      "6) Guardando dataset limpio...\n",
      "‚úÖ Guardado completado: ../data/processed/cleaned_customer_loyalty_flights.csv\n",
      "Filas finales: 401688 | Columnas finales: 25\n",
      "\n",
      "üìå Resumen final de nulos (top 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cancellation_year</th>\n",
       "      <td>352080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_month</th>\n",
       "      <td>352080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flights_with_companions</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_flights</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flights_booked</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loyalty_number</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>points_redeemed</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          nulos\n",
       "cancellation_year        352080\n",
       "cancellation_month       352080\n",
       "month                         0\n",
       "year                          0\n",
       "flights_with_companions       0\n",
       "total_flights                 0\n",
       "distance                      0\n",
       "flights_booked                0\n",
       "loyalty_number                0\n",
       "points_redeemed               0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loyalty_number</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>flights_booked</th>\n",
       "      <th>flights_with_companions</th>\n",
       "      <th>total_flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>points_accumulated</th>\n",
       "      <th>points_redeemed</th>\n",
       "      <th>dollar_cost_points_redeemed</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>salary</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>loyalty_card</th>\n",
       "      <th>clv</th>\n",
       "      <th>enrollment_type</th>\n",
       "      <th>enrollment_year</th>\n",
       "      <th>enrollment_month</th>\n",
       "      <th>cancellation_year</th>\n",
       "      <th>cancellation_month</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100018</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1521</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>T9G 1W3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>92552.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>7919.2</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100018</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1320</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>T9G 1W3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>92552.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>7919.2</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100018</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>2533</td>\n",
       "      <td>253.0</td>\n",
       "      <td>438</td>\n",
       "      <td>36</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>T9G 1W3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>92552.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>7919.2</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loyalty_number  year  month  flights_booked  flights_with_companions  \\\n",
       "0          100018  2017      1               3                        0   \n",
       "1          100018  2017      2               2                        2   \n",
       "2          100018  2017      3              14                        3   \n",
       "\n",
       "   total_flights  distance  points_accumulated  points_redeemed  \\\n",
       "0              3      1521               152.0                0   \n",
       "1              4      1320               132.0                0   \n",
       "2             17      2533               253.0              438   \n",
       "\n",
       "   dollar_cost_points_redeemed province      city postal_code  gender  \\\n",
       "0                            0  Alberta  Edmonton     T9G 1W3  Female   \n",
       "1                            0  Alberta  Edmonton     T9G 1W3  Female   \n",
       "2                           36  Alberta  Edmonton     T9G 1W3  Female   \n",
       "\n",
       "  education   salary marital_status loyalty_card     clv enrollment_type  \\\n",
       "0  Bachelor  92552.0        Married       Aurora  7919.2        Standard   \n",
       "1  Bachelor  92552.0        Married       Aurora  7919.2        Standard   \n",
       "2  Bachelor  92552.0        Married       Aurora  7919.2        Standard   \n",
       "\n",
       "   enrollment_year  enrollment_month  cancellation_year  cancellation_month  \\\n",
       "0             2016                 8               <NA>                <NA>   \n",
       "1             2016                 8               <NA>                <NA>   \n",
       "2             2016                 8               <NA>                <NA>   \n",
       "\n",
       "   cancelled  \n",
       "0      False  \n",
       "1      False  \n",
       "2      False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ejecuci√≥n de la funci√≥n de limpieza\n",
    "\n",
    "df_limpio = limpiar_dataset(df)\n",
    "display(df_limpio.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bootcamp)",
   "language": "python",
   "name": "bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
